{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import keras\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "hide_input": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mmde-lab/anaconda3/envs/whxPyEnv/lib/python3.6/site-packages/IPython/core/interactiveshell.py:2728: DtypeWarning: Columns (9,14,15,51,56) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n",
      "/home/mmde-lab/anaconda3/envs/whxPyEnv/lib/python3.6/site-packages/IPython/core/interactiveshell.py:2728: DtypeWarning: Columns (10,13,26,31) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n",
      "/home/mmde-lab/anaconda3/envs/whxPyEnv/lib/python3.6/site-packages/IPython/core/interactiveshell.py:2728: DtypeWarning: Columns (0,3,9,10,13,17,18,24,25,26,29,30,31) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "work_path = '/home/mmde-lab/s3/59e875d818c7b/'\n",
    "deal_path = 'kddi_r_deal.tsv_20180328.gz'\n",
    "deal_profile_path = 'kddi_r_deal_profile_20180427.tsv.gz'\n",
    "deal_profile_path2 = 'kddi_r_deal_profile_20171222.tsv.gz'\n",
    "df_deal = pd.read_csv(work_path + deal_path, sep = '\\t', compression='gzip')\n",
    "df_dealprofile = pd.read_csv(work_path + deal_profile_path, sep = '\\t', compression='gzip')\n",
    "df_dealprofile2 = pd.read_csv(work_path + deal_profile_path2, sep = '\\t', compression='gzip')\n",
    "\n",
    "df_deal = df_deal.dropna(axis=1, thresh= 270000)\n",
    "\n",
    "df_dealprofile = df_dealprofile.append(df_dealprofile2)\n",
    "df_dealprofile = df_dealprofile[['deal_id', 'limitation_cd', 'fixed_about_reserve_add_flg','reservation_visible_flg', 'reservation_required_flg','fixed_about_gift_add_flg','del_flg']]\n",
    "\n",
    "dealpro_cat_col = ['limitation_cd', 'fixed_about_reserve_add_flg','reservation_visible_flg', 'reservation_required_flg','fixed_about_gift_add_flg','del_flg']\n",
    "deal_num_col = ['deal_price','max_amount', 'min_amount', 'set_amount', 'remind_mail', 'after_purchase_remind_mail','max_amount_per_account', 'min_amount_per_account',]\n",
    "deal_cat_col = ['branch_deal_flg', 'deal_type_cd', 'sales_method', 'deal_category_cd', 'deal_status', 'fixed_price_name', 'usable_day_visible_flg', 'ordered_flg', 'soldout_flg','strategy_flg', 'account_duplicate_chk_flg', 'template_flg', 'mobile_usable_flg', 'booking_system_flg', 'np_cart_flg', 'sales_progress_flg', 'fixed_score_boost_flg', 'wm_fixed_score_boost_flg', 'featured_flg', 'preferential_flg', 'loto_flg', 'deal_visible_cd', 'sku_default_visible_flg', 'purchase_count_visible_flg', 'api_visible_flg', 'correspondence_education_flg', 'want_visible_flg', 'dummy_deal_flg', 'max_amount_upd_flg', 'furusato_flg']\n",
    "\n",
    "df_deal = df_deal[['deal_id'] + deal_num_col + deal_cat_col]\n",
    "\n",
    "from gensim import corpora\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "def cate2OneHot(Cfeature):\n",
    "    label_encoder = LabelEncoder()\n",
    "    integer_encoded = label_encoder.fit_transform(Cfeature)\n",
    "    encoded = to_categorical(integer_encoded)\n",
    "    return pd.DataFrame(encoded)\n",
    "\n",
    "df_dealprofile = df_dealprofile.dropna()\n",
    "df_deal = df_deal.dropna()\n",
    "\n",
    "df_dealprofile = df_dealprofile.reset_index(drop=True)\n",
    "df_deal = df_deal.reset_index(drop=True)\n",
    "\n",
    "for column in dealpro_cat_col:\n",
    "    df_dealprofile = pd.concat([df_dealprofile,cate2OneHot(df_dealprofile[column]).rename(columns = lambda x: str(column)+'_' + str(x))], axis = 1)\n",
    "\n",
    "for column in deal_cat_col:\n",
    "    df_deal = pd.concat([df_deal,cate2OneHot(df_deal[column]).rename(columns = lambda x: str(column)+'_' + str(x))], axis = 1)\n",
    "\n",
    "df_dealprofile.drop(dealpro_cat_col, axis=1,inplace=True)\n",
    "df_deal.drop(deal_cat_col, axis=1, inplace=True)\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "data_scaler = StandardScaler()\n",
    "\n",
    "df_deal[deal_num_col] = data_scaler.fit_transform(df_deal[deal_num_col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_embedded_vector(cb_or_sb):\n",
    "    if cb_or_sb == 'cb':\n",
    "        df_deal_vec = pd.read_csv('df_item_cbwin5_trainset.csv.gz', compression='gzip')\n",
    "        df_user_vec = pd.read_csv('df_user_cbwin5_trainset.csv.gz', compression='gzip')\n",
    "        df_deal_vec.dealvec = df_deal_vec.dealvec.map(lambda x: x[2:-2].split())\n",
    "    if cb_or_sb == 'sb':\n",
    "        df_deal_vec = pd.read_csv('df_item_sbwin5_trainset.csv.gz', compression='gzip')\n",
    "        df_user_vec = pd.read_csv('df_user_sbwin5_trainset.csv.gz', compression='gzip')\n",
    "        df_deal_vec.dealvec = df_deal_vec.dealvec.map(lambda x: x[1:-1].split())\n",
    "    df_deal_vec = df_deal_vec[['deal_id', 'dealvec']]\n",
    "    df_user_vec = df_user_vec[['account_id', 'uservec']]\n",
    "    df_user_vec.uservec = df_user_vec.uservec.map(lambda x: x[2:-2].split())\n",
    "\n",
    "    for i in range(200):\n",
    "        df_deal_vec['dealvec_' + cb_or_sb + str(i)] = df_deal_vec.dealvec.map(lambda x: float(x[i]))\n",
    "    for i in range(200):\n",
    "        df_user_vec['uservec_'+ cb_or_sb + str(i)] = df_user_vec.uservec.map(lambda x: float(x[i]))\n",
    "    return df_deal_vec, df_user_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_deal_vec_sb, df_user_vec_sb = read_embedded_vector('sb')\n",
    "df_deal_vec_cb, df_user_vec_cb = read_embedded_vector('cb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new_user_vec = pd.read_csv('df_user_sb_trainset_newmethod.csv.gz', compression='gzip')\n",
    "df_new_user_vec.uservec = df_new_user_vec.uservec.map(lambda x: x[1:-1].split())\n",
    "for i in range(200):\n",
    "    df_new_user_vec['new_uservec_'+ 'sb' + str(i)] = df_new_user_vec.uservec.map(lambda x: float(x[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_vec_name = []\n",
    "deal_vec_name = []\n",
    "for i in range(200):\n",
    "    user_vec_name.append('uservec_sb' + str(i))\n",
    "    deal_vec_name.append('dealvec_sb' + str(i))\n",
    "\n",
    "cb_user_vec_name = []\n",
    "cb_deal_vec_name = []\n",
    "for i in range(200):\n",
    "    cb_user_vec_name.append('uservec_cb' + str(i))\n",
    "    cb_deal_vec_name.append('dealvec_cb' + str(i))\n",
    "new_user_vec_name = []\n",
    "for i in range(200):\n",
    "    new_user_vec_name.append('new_uservec_sb' + str(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "data_scaler = StandardScaler()\n",
    "\n",
    "df_deal_vec_sb[deal_vec_name] = data_scaler.fit_transform(df_deal_vec_sb[deal_vec_name])\n",
    "df_user_vec_sb[user_vec_name] = data_scaler.fit_transform(df_user_vec_sb[user_vec_name])\n",
    "df_deal_vec_cb[cb_deal_vec_name] = data_scaler.fit_transform(df_deal_vec_cb[cb_deal_vec_name])\n",
    "df_user_vec_cb[cb_user_vec_name] = data_scaler.fit_transform(df_user_vec_cb[cb_user_vec_name])\n",
    "df_new_user_vec[new_user_vec_name] = data_scaler.fit_transform(df_new_user_vec[new_user_vec_name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": true
   },
   "outputs": [],
   "source": [
    "# random split train_test\n",
    "deal_order = pd.read_csv('/home/mmde-lab/lizhi/Naive RS/' + 'df_order_add_negasmpl.gz', compression = 'gzip')\n",
    "deal_order = deal_order[['account_id', 'deal_id', 'rating']]\n",
    "df_order_after = pd.merge(deal_order, df_deal_vec, how='left', left_on=['deal_id'], right_on=['deal_id'])\n",
    "df_order_after = pd.merge(df_order_after, df_user_vec, how='left', left_on=['account_id'], right_on=['account_id'])\n",
    "df_order_after = df_order_after.dropna()\n",
    "from sklearn.model_selection import train_test_split\n",
    "train_order_after, test_order_after = train_test_split(df_order_after, test_size = 0.1)\n",
    "train_order_after, valid_order_after = train_test_split(train_order_after, test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split train_test by time\n",
    "work_path = '/home/mmde-lab/lizhi/Naive RS/'\n",
    "train_order_path = 'train_order_add_negasmpl.gz'\n",
    "train_order_dc_path = 'train_order_add_negasmpl_dealcnt.gz'\n",
    "valid_order_dc_path = 'valid_order_add_negasmpl_dealcnt.gz'\n",
    "valid_order_uc_path ='valid_order_add_negasmpl.gz'\n",
    "test_order_uc_path = 'test_order_add_negasmpl.gz'\n",
    "test_order_dc_path = 'test_order_add_negasmpl_dealcnt.gz'\n",
    "test_order_sguc_path ='test_order_simple_sample_uc.gz'\n",
    "test_order_sgdc_path = 'test_order_single_sample.gz'\n",
    "test_order_ful_path = 'test_order_fully_distribution.gz'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_embedded_vec(df_path):\n",
    "    df = pd.read_csv(work_path + df_path, compression='gzip')\n",
    "    df = df[['account_id', 'deal_id', 'rating']]\n",
    "    df_new = pd.merge(df, df_deal_vec_sb, how='left', left_on=['deal_id'], right_on=['deal_id'])\n",
    "    df_new = pd.merge(df_new, df_user_vec_sb, how='left', left_on=['account_id'], right_on=['account_id'])\n",
    "    df_new = pd.merge(df_new, df_deal_vec_cb, how='left', left_on=['deal_id'], right_on=['deal_id'])\n",
    "    df_new = pd.merge(df_new, df_user_vec_cb, how='left', left_on=['account_id'], right_on=['account_id'])\n",
    "    df_new = pd.merge(df_new, df_new_user_vec, how='left', left_on=['account_id'], right_on=['account_id'])\n",
    "    df_new = df_new.dropna()\n",
    "    return df_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mmde-lab/anaconda3/envs/whxPyEnv/lib/python3.6/site-packages/IPython/core/interactiveshell.py:2850: DtypeWarning: Columns (2,4) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  if self.run_code(code, result):\n"
     ]
    }
   ],
   "source": [
    "train_order = merge_embedded_vec(train_order_path)\n",
    "train_order_dc = merge_embedded_vec(train_order_dc_path)\n",
    "valid_order_dc = merge_embedded_vec(valid_order_dc_path)\n",
    "valid_order_uc = merge_embedded_vec(valid_order_uc_path)\n",
    "test_order_uc = merge_embedded_vec(test_order_uc_path)\n",
    "test_order_dc = merge_embedded_vec(test_order_dc_path)\n",
    "test_order_sguc = merge_embedded_vec(test_order_sguc_path)\n",
    "test_order_sgdc = merge_embedded_vec(test_order_sgdc_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mmde-lab/anaconda3/envs/whxPyEnv/lib/python3.6/site-packages/IPython/core/interactiveshell.py:2850: DtypeWarning: Columns (2,4) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  if self.run_code(code, result):\n"
     ]
    }
   ],
   "source": [
    "test_order_ful = merge_embedded_vec(test_order_ful_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_list = deal_vec_name + user_vec_name + cb_deal_vec_name + cb_user_vec_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_dc, train_dev_dc = train_test_split(train_order_dc, test_size = 0.01)\n",
    "train_uc, train_dev_uc = train_test_split(train_order, test_size = 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "hide_input": true
   },
   "outputs": [],
   "source": [
    "train_order_after = pd.merge(train_order_after, df_deal, how='left', left_on=['deal_id'], right_on=['deal_id'])\n",
    "valid_order_after = pd.merge(valid_order_after, df_deal, how='left', left_on=['deal_id'], right_on=['deal_id'])\n",
    "test_order_after = pd.merge(test_order_after, df_deal, how='left', left_on=['deal_id'], right_on=['deal_id'])\n",
    "\n",
    "train_order_after = pd.merge(train_order_after, df_dealprofile, how='left', left_on=['deal_id'], right_on=['deal_id'])\n",
    "valid_order_after = pd.merge(valid_order_after, df_dealprofile, how='left', left_on=['deal_id'], right_on=['deal_id'])\n",
    "test_order_after = pd.merge(test_order_after, df_dealprofile, how='left', left_on=['deal_id'], right_on=['deal_id'])\n",
    "\n",
    "deal_feature = ['deal_price', 'max_amount', 'min_amount', 'set_amount',\n",
    "       'remind_mail', 'after_purchase_remind_mail',\n",
    "       'max_amount_per_account', 'min_amount_per_account',\n",
    "       'branch_deal_flg_0', 'branch_deal_flg_1', 'deal_type_cd_0',\n",
    "       'deal_type_cd_1', 'deal_type_cd_2', 'deal_type_cd_3',\n",
    "       'sales_method_0', 'sales_method_1', 'deal_category_cd_0',\n",
    "       'deal_category_cd_1', 'deal_category_cd_2', 'deal_category_cd_3',\n",
    "       'deal_category_cd_4', 'deal_category_cd_5', 'deal_category_cd_6',\n",
    "       'deal_category_cd_7', 'deal_category_cd_8', 'deal_category_cd_9',\n",
    "       'deal_category_cd_10', 'deal_category_cd_11',\n",
    "       'deal_category_cd_12', 'deal_status_0', 'deal_status_1',\n",
    "       'fixed_price_name_0', 'fixed_price_name_1', 'fixed_price_name_2',\n",
    "       'usable_day_visible_flg_0', 'usable_day_visible_flg_1',\n",
    "       'ordered_flg_0', 'ordered_flg_1', 'soldout_flg_0', 'soldout_flg_1',\n",
    "       'strategy_flg_0', 'strategy_flg_1', 'account_duplicate_chk_flg_0',\n",
    "       'account_duplicate_chk_flg_1', 'template_flg_0', 'template_flg_1',\n",
    "       'mobile_usable_flg_0', 'mobile_usable_flg_1',\n",
    "       'booking_system_flg_0', 'booking_system_flg_1', 'np_cart_flg_0',\n",
    "       'np_cart_flg_1', 'sales_progress_flg_0', 'sales_progress_flg_1',\n",
    "       'fixed_score_boost_flg_0', 'fixed_score_boost_flg_1',\n",
    "       'wm_fixed_score_boost_flg_0', 'wm_fixed_score_boost_flg_1',\n",
    "       'featured_flg_0', 'featured_flg_1', 'preferential_flg_0',\n",
    "       'preferential_flg_1', 'loto_flg_0', 'loto_flg_1',\n",
    "       'deal_visible_cd_0', 'deal_visible_cd_1', 'deal_visible_cd_2',\n",
    "       'deal_visible_cd_3', 'deal_visible_cd_4', 'deal_visible_cd_5',\n",
    "       'deal_visible_cd_6', 'sku_default_visible_flg_0',\n",
    "       'sku_default_visible_flg_1', 'purchase_count_visible_flg_0',\n",
    "       'purchase_count_visible_flg_1', 'api_visible_flg_0',\n",
    "       'api_visible_flg_1', 'correspondence_education_flg_0',\n",
    "       'correspondence_education_flg_1', 'want_visible_flg_0',\n",
    "       'want_visible_flg_1', 'dummy_deal_flg_0', 'dummy_deal_flg_1',\n",
    "       'max_amount_upd_flg_0', 'max_amount_upd_flg_1', 'furusato_flg_0',\n",
    "       'furusato_flg_1']\n",
    "\n",
    "dealpro_feature = ['limitation_cd_0', 'limitation_cd_1', 'limitation_cd_2',\n",
    "       'limitation_cd_3', 'fixed_about_reserve_add_flg_0',\n",
    "       'fixed_about_reserve_add_flg_1', 'reservation_visible_flg_0',\n",
    "       'reservation_visible_flg_1', 'reservation_required_flg_0',\n",
    "       'reservation_required_flg_1', 'fixed_about_gift_add_flg_0',\n",
    "       'fixed_about_gift_add_flg_1', 'del_flg_0']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ----------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Input, Dense, Concatenate, Flatten, BatchNormalization, Dropout\n",
    "from keras.losses import binary_crossentropy, mse\n",
    "from keras import regularizers\n",
    "from sklearn.metrics import accuracy_score, f1_score, recall_score, precision_score, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "session_user_input = Input(shape=(200,), name='sb_user_vec')\n",
    "session_deal_input = Input(shape=(200,), name='sb_deal_vec')\n",
    "content_user_input = Input(shape=(200,), name='cb_user_vec')\n",
    "content_deal_input = Input(shape=(200,), name='cb_deal_vec')\n",
    "session_concat = Concatenate()([session_user_input, session_deal_input])\n",
    "content_concat = Concatenate()([content_user_input, content_deal_input])\n",
    "#concat = Concatenate()([session_user_input, content_deal_input])\n",
    "\n",
    "#fc_sb0 = Dense(512, activation='relu')(session_concat)\n",
    "fc_sb1 = Dense(128, activation='relu',kernel_regularizer=regularizers.l2(0.01))(session_concat)\n",
    "dropout_sb1 = Dropout(0.0)(fc_sb1)\n",
    "#fc_sb2 = Dense(256, activation='relu')(fc_sb1)\n",
    "fc_sb2 = Dense(128, activation='relu',kernel_regularizer=regularizers.l2(0.01))(dropout_sb1)\n",
    "dropout_sb2 = Dropout(0.0)(fc_sb2)\n",
    "fc_sb3 = Dense(128, activation='relu',kernel_regularizer=regularizers.l2(0.01))(dropout_sb2)\n",
    "dropout_sb3 = Dropout(0.0)(fc_sb3)\n",
    "fc_sb4 = Dense(64, activation='relu',kernel_regularizer=regularizers.l2(0.01))(dropout_sb3)\n",
    "\n",
    "#fc_cb0 = Dense(512, activation='relu')(content_concat)\n",
    "fc_cb1 = Dense(128, activation='relu',kernel_regularizer=regularizers.l2(0.01))(content_concat)\n",
    "dropout_cb1 = Dropout(0.0)(fc_cb1)\n",
    "#fc_cb2 = Dense(256, activation='relu')(fc_cb1)\n",
    "fc_cb2 = Dense(128, activation='relu',kernel_regularizer=regularizers.l2(0.01))(dropout_cb1)\n",
    "dropout_cb2 = Dropout(0.0)(fc_cb2)\n",
    "fc_cb3 = Dense(128, activation='relu',kernel_regularizer=regularizers.l2(0.01))(dropout_cb2)\n",
    "dropout_cb3 = Dropout(0.0)(fc_cb3)\n",
    "fc_cb4 = Dense(64, activation='relu',kernel_regularizer=regularizers.l2(0.01))(dropout_cb3)\n",
    "\n",
    "concat = Concatenate()([fc_sb4, fc_cb4])\n",
    "dropout_con = Dropout(0.0)(concat)\n",
    "output = Dense(1, activation='sigmoid',kernel_regularizer=regularizers.l2(0.01))(dropout_con)\n",
    "\n",
    "model = Model(inputs = [ session_deal_input, session_user_input, content_deal_input, content_user_input], outputs=output)\n",
    "#model = Model(inputs = [session_user_input, content_deal_input], outputs=output)\n",
    "model.compile(optimizer='adam',loss=binary_crossentropy, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "sb_user_vec (InputLayer)        (None, 200)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "sb_deal_vec (InputLayer)        (None, 200)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "cb_user_vec (InputLayer)        (None, 200)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "cb_deal_vec (InputLayer)        (None, 200)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 400)          0           sb_user_vec[0][0]                \n",
      "                                                                 sb_deal_vec[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 400)          0           cb_user_vec[0][0]                \n",
      "                                                                 cb_deal_vec[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 128)          51328       concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 128)          51328       concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 128)          0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 128)          0           dense_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 128)          16512       dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 128)          16512       dropout_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 128)          0           dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)             (None, 128)          0           dense_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 128)          16512       dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_7 (Dense)                 (None, 128)          16512       dropout_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 128)          0           dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)             (None, 128)          0           dense_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 64)           8256        dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_8 (Dense)                 (None, 64)           8256        dropout_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 128)          0           dense_4[0][0]                    \n",
      "                                                                 dense_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_7 (Dropout)             (None, 128)          0           concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_9 (Dense)                 (None, 1)            129         dropout_7[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 185,345\n",
      "Trainable params: 185,345\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3134213 samples, validate on 68103 samples\n",
      "Epoch 1/100\n",
      "3134213/3134213 [==============================] - 143s 46us/step - loss: 0.3573 - acc: 0.9293 - val_loss: 0.9818 - val_acc: 0.6796\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.98184, saving model to model.hdf5\n",
      "Epoch 2/100\n",
      "3134213/3134213 [==============================] - 143s 46us/step - loss: 0.3495 - acc: 0.9335 - val_loss: 0.9205 - val_acc: 0.6997\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.98184 to 0.92046, saving model to model.hdf5\n",
      "Epoch 3/100\n",
      "3134213/3134213 [==============================] - 143s 46us/step - loss: 0.3493 - acc: 0.9338 - val_loss: 0.8879 - val_acc: 0.7044\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.92046 to 0.88791, saving model to model.hdf5\n",
      "Epoch 4/100\n",
      "3134213/3134213 [==============================] - 143s 46us/step - loss: 0.3484 - acc: 0.9344 - val_loss: 1.0639 - val_acc: 0.6607\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.88791\n",
      "Epoch 5/100\n",
      "3134213/3134213 [==============================] - 143s 46us/step - loss: 0.3482 - acc: 0.9345 - val_loss: 0.9865 - val_acc: 0.6762\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.88791\n",
      "Epoch 6/100\n",
      "3134213/3134213 [==============================] - 143s 46us/step - loss: 0.3483 - acc: 0.9344 - val_loss: 0.9869 - val_acc: 0.6798\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.88791\n",
      "Epoch 00006: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nmodel.fit([train_order_after.loc[:, cb_user_vec_name].values, train_order_after.loc[:, cb_deal_vec_name].values], train_order_after.rating, \\n          validation_data=([valid_order_after.loc[:, cb_user_vec_name].values, valid_order_after.loc[:, cb_deal_vec_name].values], valid_order_after.rating),\\n          batch_size=1024,\\n          epochs=100, \\n          verbose=True,\\n         callbacks=[early_stop, check_point])\\n'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "check_point = ModelCheckpoint('model.hdf5', verbose=True, save_best_only = True)\n",
    "early_stop = EarlyStopping(patience=3, verbose=True)\n",
    "\n",
    "import keras.backend as K\n",
    "\n",
    "model.fit([train_dc.loc[:, deal_vec_name].values, train_dc.loc[:, user_vec_name].values, train_dc.loc[:, cb_deal_vec_name].values, train_dc.loc[:, cb_user_vec_name].values], train_dc.rating, \n",
    "          validation_data=([valid_order_dc.loc[:, deal_vec_name].values, valid_order_dc.loc[:, user_vec_name].values, valid_order_dc.loc[:, cb_deal_vec_name].values, valid_order_dc.loc[:, cb_user_vec_name].values], valid_order_dc.rating),\n",
    "          batch_size=512,\n",
    "          epochs=100, \n",
    "          verbose=True,\n",
    "         callbacks=[early_stop, check_point])\n",
    "'''\n",
    "model.fit([train_order_after.loc[:, cb_user_vec_name].values, train_order_after.loc[:, cb_deal_vec_name].values], train_order_after.rating, \n",
    "          validation_data=([valid_order_after.loc[:, cb_user_vec_name].values, valid_order_after.loc[:, cb_deal_vec_name].values], valid_order_after.rating),\n",
    "          batch_size=1024,\n",
    "          epochs=100, \n",
    "          verbose=True,\n",
    "         callbacks=[early_stop, check_point])\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": true
   },
   "outputs": [],
   "source": [
    "session_user_input = Input(shape=(200,), name='sb_user_vec')\n",
    "session_deal_input = Input(shape=(200,), name='sb_deal_vec')\n",
    "content_user_input = Input(shape=(200,), name='cb_user_vec')\n",
    "content_deal_input = Input(shape=(200,), name='cb_deal_vec')\n",
    "deal_feature_input = Input(shape=(len(deal_feature)+ len(dealpro_feature),), name='deal_feature')\n",
    "session_concat = Concatenate()([session_user_input, session_deal_input])\n",
    "content_concat = Concatenate()([content_user_input, content_deal_input])\n",
    "\n",
    "fc_sb0 = Dense(512, activation='relu')(session_concat)\n",
    "fc_sb1 = Dense(256, activation='relu')(fc_sb0)\n",
    "#dropout_1 = Dropout(0.2)(fc_1)\n",
    "fc_sb2 = Dense(256, activation='relu')(fc_sb1)\n",
    "fc_sb3 = Dense(128, activation='relu')(fc_sb2)\n",
    "#dropout_2 = Dropout(0.2)(fc_3)\n",
    "fc_sb4 = Dense(64, activation='relu')(fc_sb3)\n",
    "fc_sb5 = Dense(16, activation='relu')(fc_sb4)\n",
    "\n",
    "fc_cb0 = Dense(512, activation='relu')(content_concat)\n",
    "fc_cb1 = Dense(256, activation='relu')(fc_cb0)\n",
    "#dropout_1 = Dropout(0.2)(fc_1)\n",
    "fc_cb2 = Dense(256, activation='relu')(fc_cb1)\n",
    "fc_cb3 = Dense(128, activation='relu')(fc_cb2)\n",
    "#dropout_2 = Dropout(0.2)(fc_3)\n",
    "fc_cb4 = Dense(64, activation='relu')(fc_cb3)\n",
    "fc_cb5 = Dense(16, activation='relu')(fc_cb4)\n",
    "\n",
    "\n",
    "fc_deal0 = Dense(128, activation='relu')(deal_feature_input)\n",
    "fc_deal1 = Dense(64, activation='relu')(fc_deal0)\n",
    "fc_deal2 = Dense(8, activation='relu')(fc_deal1)\n",
    "\n",
    "concat = Concatenate()([fc_sb5, fc_cb5, fc_deal2])\n",
    "dense_0 = Dense(16, activation='relu')(concat)\n",
    "output = Dense(1, activation='sigmoid')(dense_0)\n",
    "\n",
    "model = Model(inputs = [session_user_input, session_deal_input, content_user_input, content_deal_input, deal_feature_input], outputs=output)\n",
    "model.compile(optimizer='adam',loss=binary_crossentropy, metrics=['accuracy'])\n",
    "\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "check_point = ModelCheckpoint('model.hdf5', verbose=True, save_best_only = True)\n",
    "early_stop = EarlyStopping(patience=5, verbose=True)\n",
    "\n",
    "\n",
    "import keras.backend as K\n",
    "from keras.callbacks import LearningRateScheduler\n",
    " \n",
    "def scheduler(epoch):\n",
    "    # 每隔100个epoch，学习率减小为原来的1/10\n",
    "    if epoch % 100 == 0 and epoch != 0:\n",
    "        lr = K.get_value(model.optimizer.lr)\n",
    "        K.set_value(model.optimizer.lr, lr * 0.1)\n",
    "        print(\"lr changed to {}\".format(lr * 0.1))\n",
    "    return K.get_value(model.optimizer.lr)\n",
    " \n",
    "reduce_lr = LearningRateScheduler(scheduler)\n",
    "model.fit([train_order_after.loc[:, user_vec_name].values, train_order_after.loc[:, deal_vec_name].values, train_order_after.loc[:, cb_user_vec_name].values, train_order_after.loc[:, cb_deal_vec_name].values, train_order_after.loc[:, deal_feature+dealpro_feature].values], train_order_after.rating, \n",
    "          validation_data=([valid_order_after.loc[:, user_vec_name].values, valid_order_after.loc[:, deal_vec_name].values, valid_order_after.loc[:, cb_user_vec_name].values, valid_order_after.loc[:, cb_deal_vec_name].values, valid_order_after.loc[:, deal_feature+dealpro_feature].values], valid_order_after.rating),\n",
    "          batch_size=128,\n",
    "          epochs=100, \n",
    "          verbose=True,\n",
    "         callbacks=[early_stop, check_point, reduce_lr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights('model.hdf5')\n",
    "#cb\n",
    "#pred_result = model.predict([test_order_after.loc[:, user_vec_name].values, test_order_after.loc[:, cb_deal_vec_name].values])\n",
    "#sb\n",
    "#pred_result = model.predict([test_order_after.loc[:, user_vec_name].values, test_order_after.loc[:, deal_vec_name].values])\n",
    "#cb+sb\n",
    "#pred_result = model.predict([test_order_dc.loc[:, deal_vec_name].values, test_order_dc.loc[:, new_user_vec_name].values, test_order_dc.loc[:, cb_deal_vec_name].values, test_order_dc.loc[:, cb_user_vec_name].values])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_pred(df):\n",
    "    pred_result = model.predict([df.loc[:, deal_vec_name].values, df.loc[:, user_vec_name].values, df.loc[:, cb_deal_vec_name].values, df.loc[:, cb_user_vec_name].values])\n",
    "    return pred_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def namestr(obj, namespace):\n",
    "    return [name for name in namespace if namespace[name] is obj]\n",
    "def print_result(df_name):\n",
    "    pred_result = model_pred(df_name)\n",
    "    for i in range(len(pred_result)):\n",
    "        pred_result[i] = int(pred_result[i][0] >= 0.5)\n",
    "    print(namestr(df_name, globals())[0] + '_accuracy: ',  accuracy_score(df_name.rating, pred_result))\n",
    "    print(classification_report(df_name.rating, pred_result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_order_ful_accuracy:  0.7136968544008248\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.71      0.83   3659416\n",
      "          1       0.00      0.58      0.00      3352\n",
      "\n",
      "avg / total       1.00      0.71      0.83   3662768\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_result(test_order_ful)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "hide_input": true
   },
   "outputs": [],
   "source": [
    "model.load_weights('model.hdf5')\n",
    "pred_result = model.predict([test_order_after.loc[:, user_vec_name].values, test_order_after.loc[:, deal_vec_name].values, test_order_after.loc[:, cb_user_vec_name].values, test_order_after.loc[:, cb_deal_vec_name].values], test_order_after.loc[:, deal_feature+dealpro_feature].values)\n",
    "np.save('nn_result.npy', pred_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    3664720\n",
       "1       3352\n",
       "Name: rating, dtype: int64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_order_uc.rating.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_result = model_pred(test_order_ful)\n",
    "for i in range(len(pred_result)):\n",
    "    pred_result[i] = int(pred_result[i][0] >= 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1049176"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(pred_result == 1).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python [conda env:whxPyEnv]",
   "language": "python",
   "name": "conda-env-whxPyEnv-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
